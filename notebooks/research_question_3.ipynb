{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator, Callable\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Any, TypeAlias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "from functools import partial, reduce\n",
    "from tqdm import tqdm\n",
    "from IPython.display import (\n",
    "    display, # type: ignore[reportUnknownVariableType]\n",
    "    Markdown,\n",
    ")\n",
    "\n",
    "from config.fastf1 import fastf1\n",
    "from config import config\n",
    "from src.data.loader import stream_ndjson, load_submissions_df, load_comments_df\n",
    "from src.data.preprocessing import concatenate_submissions_and_comments\n",
    "import src.data.constants as dataset_constants\n",
    "\n",
    "from src.utils import (\n",
    "    temporary_pandas_options,\n",
    "    display_full_dataframe,\n",
    "    hide_index,\n",
    "    compose,\n",
    ")\n",
    "from src import utils\n",
    "utils.set_random_seeds()\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fastf1').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ndjson_streamer = partial(stream_ndjson, limit=5000)\n",
    "\n",
    "f1_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, f1_ndjson_streamer)\n",
    "f1_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1_COMMENTS, f1_ndjson_streamer)\n",
    "\n",
    "f15_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1POINT5_SUBMISSIONS)\n",
    "f15_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1POINT5_COMMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 submissions:'), f1_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1 comments:'), f1_comments_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 submissions:'), f15_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 comments:'), f15_comments_df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = concatenate_submissions_and_comments(f1_submissions_df, f1_comments_df)\n",
    "f15_df = concatenate_submissions_and_comments(f15_submissions_df, f15_comments_df)\n",
    "\n",
    "n = 3\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 posts:'), f1_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 posts:'), f15_df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare Data\n",
    "# Assuming `processed_data` is a list of preprocessed sentences (tokenized, lemmatized, etc.)\n",
    "processed_data = [\n",
    "    ['ricciardo', 'to', 'red', 'bull'],\n",
    "    ['hamilton', 'to', 'stay', 'mercedes'],\n",
    "    ['alonso', 'to', 'aston', 'martin'],\n",
    "    # Add more sentences from your dataset\n",
    "]\n",
    "\n",
    "preprocessed_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create N-grams and Train Model\n",
    "def train_ngram_model(data, n=2):\n",
    "    ngram_counts = defaultdict(Counter)\n",
    "    total_counts = Counter()\n",
    "\n",
    "    for sentence in data:\n",
    "        sentence = ['<s>'] + sentence + ['</s>']  # Add start and end tokens\n",
    "        n_grams = list(ngrams(sentence, n))\n",
    "        for gram in n_grams:\n",
    "            prefix, next_word = tuple(gram[:-1]), gram[-1]\n",
    "            ngram_counts[prefix][next_word] += 1\n",
    "            total_counts[prefix] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    ngram_probs = {\n",
    "        prefix: {word: count / total_counts[prefix] for word, count in words.items()}\n",
    "        for prefix, words in ngram_counts.items()\n",
    "    }\n",
    "\n",
    "    return ngram_probs\n",
    "\n",
    "# Train a bigram model\n",
    "bigram_model = train_ngram_model(processed_data, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Predict Next Word\n",
    "def predict_next_word(model, input_text, n=2):\n",
    "    tokens = input_text.lower().split()\n",
    "    prefix = tuple(tokens[-(n-1):])  # Use last (n-1) words as prefix\n",
    "    if prefix in model:\n",
    "        return max(model[prefix], key=model[prefix].get)  # Return word with highest probability\n",
    "    else:\n",
    "        return \"<unk>\"  # Return unknown token if prefix not found\n",
    "\n",
    "# Example usage\n",
    "input_text = \"ricciardo to\"\n",
    "next_word = predict_next_word(bigram_model, input_text, n=2)\n",
    "print(f\"Next word: {next_word}\")\n",
    "\n",
    "# Bonus: Generate full predictions\n",
    "def generate_predictions(model, seed_text, n=2, max_length=10):\n",
    "    tokens = seed_text.lower().split()\n",
    "    for _ in range(max_length):\n",
    "        next_word = predict_next_word(model, \" \".join(tokens), n=n)\n",
    "        if next_word == \"</s>\":\n",
    "            break\n",
    "        tokens.append(next_word)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Generate a prediction\n",
    "seed_text = \"ricciardo to\"\n",
    "prediction = generate_predictions(bigram_model, seed_text, n=2)\n",
    "print(f\"Generated prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
