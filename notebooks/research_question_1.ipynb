{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator, Callable\n",
    "from pathlib import Path\n",
    "import typing\n",
    "from typing import Any, TypeAlias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re\n",
    "from functools import partial, reduce\n",
    "from tqdm import tqdm\n",
    "from IPython.display import (\n",
    "    display, # type: ignore[reportUnknownVariableType]\n",
    "    Markdown,\n",
    ")\n",
    "\n",
    "import importlib\n",
    "\n",
    "from config.fastf1 import fastf1\n",
    "from config import config\n",
    "import src.data.constants as dataset_constants\n",
    "importlib.reload(dataset_constants);\n",
    "import src.data.loader\n",
    "importlib.reload(src.data.loader);\n",
    "from src.data.loader import stream_ndjson, load_submissions_df, load_comments_df\n",
    "from src.data.preprocessing import concatenate_submissions_and_comments\n",
    "\n",
    "from src.utils import (\n",
    "    temporary_pandas_options,\n",
    "    display_full_dataframe,\n",
    "    hide_index,\n",
    "    compose,\n",
    ")\n",
    "from src import utils\n",
    "utils.set_random_seeds()\n",
    "DEVICE = utils.get_device()\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fastf1').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and find submissions related to steward decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_submissions_df = load_submissions_df(\n",
    "    dataset_constants.RawFile.FORMULA1_SUBMISSIONS,\n",
    "    columns=dataset_constants.DEFAULT_SUBMISSION_COLUMNS | {'permalink', 'post_hint', 'link_flair_text'},\n",
    ")                                  \n",
    "\n",
    "f1_comments_df = load_comments_df(\n",
    "    dataset_constants.RawFile.FORMULA1_COMMENTS,\n",
    "    columns=dataset_constants.DEFAULT_COMMENT_COLUMNS | {'link_id'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: testing purposes\n",
    "f1_submissions_df['permalink'] = 'www.reddit.com' + f1_submissions_df['permalink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steward_decision_related_words = {\n",
    "    'penalty', 'steward', 'decision', 'appeal', 'review', 'ruling', 'investigation', 'regulation',\n",
    "    'seconds', 'sec', \n",
    "    'collision', 'crash', 'incident', 'overtake', 'virtual safety car', 'blocking', 'brake test', 'contact',\n",
    "    'red flag', 'yellow flag', \n",
    "    'controversial', 'rigged', 'corrupt', 'bias', 'protest', 'FIA', 'document', 'infringement'}\n",
    "\n",
    "words_regex = ''.join(fr'\\b{word}\\b|' for word in steward_decision_related_words)[:-1]\n",
    "steward_decision_pattern = re.compile(words_regex, flags=re.IGNORECASE)\n",
    "\n",
    "relevant_flairs = {':post-discussion: Discussion', ':post-technical: Technical', ':post-news: News'}\n",
    "\n",
    "has_related_words = f1_submissions_df['title'].apply(lambda title: steward_decision_pattern.search(title) is not None)\n",
    "has_relevant_flairs = f1_submissions_df['link_flair_text'].isin(relevant_flairs)\n",
    "is_image_post = f1_submissions_df['post_hint'] == 'image'\n",
    "\n",
    "steward_decision_submissions_df = f1_submissions_df[has_related_words & has_relevant_flairs & is_image_post].copy()\n",
    "\n",
    "with display_full_dataframe():\n",
    "    print(len(steward_decision_submissions_df))\n",
    "    # display(steward_decision_submissions_df)\n",
    "    display(steward_decision_submissions_df.head(2))\n",
    "    display(steward_decision_submissions_df['link_flair_text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_flairs_extended = {\n",
    "    ':post-technical: Technical',\n",
    "    ':post-discussion: Discussion',\n",
    "    ':post-timed: Timed',\n",
    "    ':post-news: News',\n",
    "    ':post-misc: Misc',\n",
    "    ':post-photo: Photo',\n",
    "    ':post-statistics: Statistics',\n",
    "    ':post-video: Video',\n",
    "    ':post-daily-discussion: Daily Discussion',\n",
    "    ':post-formula-1: /r/Formula1',\n",
    "    ':post-photo: Photo /r/all',\n",
    "    ':post-news: News /r/all',\n",
    "    ':post-grand-prix: Free Practice',\n",
    "    ':post-grand-prix: Qualifying',\n",
    "    ':post-highlight: Highlight',\n",
    "    ':post-post-session: Post-Qualifying',\n",
    "    ':post-pre-session: Pre-Race',\n",
    "    ':post-grand-prix: Race',\n",
    "    ':post-highlight: Highlight /r/all',\n",
    "    ':post-post-session: Post-Race',\n",
    "    ':post-post-session: Day after Debrief',\n",
    "    ':post-featured: Featured',\n",
    "    ':post-discussion: Discussion /r/all',\n",
    "    ':post-grand-prix: Sprint',\n",
    "    ':post-post-session: Post-Sprint',\n",
    "    ':post-technical: Technical /r/all',\n",
    "}\n",
    "\n",
    "has_related_words = f1_submissions_df['title'].apply(lambda title: steward_decision_pattern.search(title) is not None)\n",
    "has_relevant_flairs = f1_submissions_df['link_flair_text'].isin(relevant_flairs_extended)\n",
    "is_image_post = f1_submissions_df['post_hint'] == 'image'\n",
    "\n",
    "_extended_steward_decision_submissions_df = f1_submissions_df[has_related_words & has_relevant_flairs & is_image_post].copy()\n",
    "\n",
    "\n",
    "# Merge the two dataframes with an indicator column\n",
    "diff = _extended_steward_decision_submissions_df.merge(steward_decision_submissions_df, how='left', indicator=True)\n",
    "\n",
    "# Keep only rows that are in dataframeA but not in dataframeB\n",
    "result = diff[diff['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "with display_full_dataframe():\n",
    "    print(f'{len(_extended_steward_decision_submissions_df)=}')\n",
    "    print(f'{len(result)=}')\n",
    "    display(result)\n",
    "    display(_extended_steward_decision_submissions_df['link_flair_text'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment_category(sentiment: float) -> str:\n",
    "    if sentiment >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: testing\n",
    "steward_decision_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, partial(stream_ndjson, limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, steward_decision_submission in steward_decision_submissions_df.iterrows():\n",
    "    submission_link_id = f't3_{steward_decision_submission['id']}'\n",
    "    comments_df = f1_comments_df[f1_comments_df['link_id'] == submission_link_id].copy()\n",
    "\n",
    "    if comments_df.empty:\n",
    "        steward_decision_submissions_df.loc[index, 'average_sentiment_vader'] = np.nan\n",
    "        continue\n",
    "    \n",
    "    NOEMER = np.abs(comments_df['score']).sum()\n",
    "    \n",
    "    if NOEMER == 0:\n",
    "        steward_decision_submissions_df.loc[index, 'average_sentiment_vader'] = np.nan\n",
    "        continue\n",
    "\n",
    "\n",
    "    comments_df.loc[:, 'compound'] = comments_df['body'].apply(\n",
    "        lambda text: analyzer.polarity_scores(text)['compound']\n",
    "    )   #creates a data series with a score (float) given an input comment\n",
    "\n",
    "    sentiment = (comments_df['compound'] * comments_df['score']).sum() / NOEMER\n",
    "    steward_decision_submissions_df.loc[index, 'average_sentiment_vader'] = sentiment\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(steward_decision_submissions_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOD: vectorize if efficiency is needed\n",
    "steward_decision_submissions_df['submission_link_id'] = 't3_' + steward_decision_submissions_df['id']\n",
    "\n",
    "filtered_comments_df = f1_comments_df[\n",
    "    f1_comments_df['link_id'].isin(steward_decision_submissions_df['submission_link_id'])\n",
    "].copy()\n",
    "\n",
    "filtered_comments_df['compound'] = filtered_comments_df['body'].apply(\n",
    "    lambda text: analyzer.polarity_scores(text)['compound']\n",
    ")\n",
    "\n",
    "def calculate_weighted_sentiment(group):\n",
    "    NOEMER = np.abs(group['score']).sum()\n",
    "    if NOEMER == 0:\n",
    "        return np.nan\n",
    "    return (group['compound'] * group['score']).sum() / NOEMER\n",
    "\n",
    "average_sentiment = filtered_comments_df.groupby('link_id').apply(calculate_weighted_sentiment)\n",
    "\n",
    "steward_decision_submissions_df['average_sentiment_vader'] = \\\n",
    "    steward_decision_submissions_df['submission_link_id'].map(average_sentiment)\n",
    "\n",
    "steward_decision_submissions_df.drop(columns=['submission_link_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "def BERT_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    sentiment_score = torch.argmax(logits, dim=1).item()  # 0: negative, 1: neutral, 2: positive\n",
    "    return (sentiment_score - 1)\n",
    "\n",
    "for index, steward_decision_submission in steward_decision_submissions_df.iterrows():\n",
    "    submission_link_id = f't3_{steward_decision_submission['id']}'\n",
    "    comments_df = f1_comments_df[f1_comments_df['link_id'] == submission_link_id].copy()\n",
    "\n",
    "    if comments_df.empty:\n",
    "        steward_decision_submissions_df.loc[index, 'average_sentiment_bert'] = np.nan\n",
    "        continue\n",
    "    \n",
    "    NOEMER = np.abs(comments_df['score']).sum()\n",
    "    \n",
    "    if NOEMER == 0:\n",
    "        steward_decision_submissions_df.loc[index, 'average_sentiment_bert'] = np.nan\n",
    "        continue\n",
    "\n",
    "    comments_df.loc[:, 'compound'] = comments_df['body'].apply(BERT_sentiment)\n",
    "        # lambda text: analyzer.polarity_scores(text)['compound']\n",
    "        # bert induced sentiment\n",
    "\n",
    "    sentiment = (comments_df['compound'] * comments_df['score']).sum() / NOEMER\n",
    "    steward_decision_submissions_df.loc[index, 'average_sentiment_bert'] = sentiment\n",
    "\n",
    "# with display_full_dataframe():\n",
    "    # display(steward_decision_submissions_df)\n",
    "    # display(steward_decision_submissions_df['average_sentiment_bert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    np.abs(steward_decision_submissions_df['average_sentiment_bert'] - steward_decision_submissions_df['average_sentiment_vader']).sum() \\\n",
    "    / len(steward_decision_submissions_df.index)\n",
    ")\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(steward_decision_submissions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
