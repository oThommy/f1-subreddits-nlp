{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "from collections.abc import Generator, Callable\n",
    "import typing\n",
    "from typing import Any, TypeAlias\n",
    "import numpy as np\n",
    "from contextlib import contextmanager\n",
    "from functools import partial, reduce\n",
    "import re\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from IPython.display import (\n",
    "    display, # type: ignore[reportUnknownVariableType]\n",
    "    Markdown,\n",
    ")\n",
    "import importlib\n",
    "import spacy\n",
    "\n",
    "from config.fastf1 import fastf1\n",
    "import fastf1.events as fastf1_events\n",
    "from config import config\n",
    "importlib.reload(config);\n",
    "from src.data.loader import stream_ndjson, load_submissions_df, load_comments_df\n",
    "import src.data.preprocessing as preprocessing\n",
    "importlib.reload(preprocessing);\n",
    "import src.data.constants as dataset_constants\n",
    "import src.utils\n",
    "importlib.reload(src.utils);\n",
    "from src.utils import (\n",
    "    temporary_pandas_options,\n",
    "    display_full_dataframe,\n",
    "    hide_index,\n",
    "    compose,\n",
    ")\n",
    "from src import utils\n",
    "utils.set_random_seeds()\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fastf1').setLevel(logging.WARNING)\n",
    "\n",
    "DEVICE = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_f1_df(limit: int | None = None, in_place: bool = True) -> pd.DataFrame:\n",
    "    ndjson_streamer = partial(stream_ndjson, limit=limit)\n",
    "\n",
    "    return preprocessing.concatenate_submissions_and_comments(\n",
    "        submissions_df=load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, ndjson_streamer),\n",
    "        comments_df=load_comments_df(dataset_constants.RawFile.FORMULA1_COMMENTS, ndjson_streamer),\n",
    "        in_place=in_place,\n",
    "    )\n",
    "\n",
    "def load_f15_df(limit: int | None = None, in_place: bool = True) -> pd.DataFrame:\n",
    "    ndjson_streamer = partial(stream_ndjson, limit=limit)\n",
    "\n",
    "    return preprocessing.concatenate_submissions_and_comments(\n",
    "        submissions_df=load_submissions_df(dataset_constants.RawFile.FORMULA1POINT5_SUBMISSIONS, ndjson_streamer),\n",
    "        comments_df=load_comments_df(dataset_constants.RawFile.FORMULA1POINT5_COMMENTS, ndjson_streamer),\n",
    "        in_place=in_place,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ndjson_streamer = partial(stream_ndjson, limit=100)\n",
    "f15_ndjson_streamer = partial(stream_ndjson, limit=100)\n",
    "\n",
    "f1_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, f1_ndjson_streamer)\n",
    "f1_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1_COMMENTS, f1_ndjson_streamer)\n",
    "\n",
    "f15_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1POINT5_SUBMISSIONS, f15_ndjson_streamer)\n",
    "f15_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1POINT5_COMMENTS, f15_ndjson_streamer)\n",
    "\n",
    "f1_df = preprocessing.concatenate_submissions_and_comments(f1_submissions_df, f1_comments_df)\n",
    "f15_df = preprocessing.concatenate_submissions_and_comments(f15_submissions_df, f15_comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 submissions:'), f1_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1 comments:'), f1_comments_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 submissions:'), f15_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 comments:'), f15_comments_df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 posts:'), f1_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 posts:'), f15_df.head(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Rule-Based Prediction Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastf1 historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schedule = fastf1.get_event_schedule(dataset_constants.YEAR)\n",
    "schedule = typing.cast(\n",
    "    fastf1_events.EventSchedule,\n",
    "    full_schedule[\n",
    "        (full_schedule['EventDate'] >= dataset_constants.START_DATE) &\n",
    "        (full_schedule['EventDate'] <= dataset_constants.END_DATE) &\n",
    "        (full_schedule['EventFormat'] == 'conventional') # TODO: Skip sprint weekends for now. Also include sprint weekends later\n",
    "    ],\n",
    ")\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(schedule.iloc[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = f1_df\n",
    "race_weekend = schedule.iloc[-1]\n",
    "first_post_at = typing.cast(dt.datetime, race_weekend['Session1DateUtc']) - dt.timedelta(days=1)\n",
    "last_post_at = typing.cast(dt.datetime, race_weekend['Session5DateUtc'])\n",
    "posts_df = posts_df[\n",
    "    (posts_df['created_utc'] >= first_post_at) &\n",
    "    (posts_df['created_utc'] <= last_post_at)\n",
    "]\n",
    "\n",
    "def get_top20(race_weekend: fastf1_events.Event) -> pd.DataFrame:\n",
    "    race_session = race_weekend.get_session('Race')\n",
    "    race_session.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "    top20 = race_session.results[['FullName', 'Position']].astype({'Position': np.uint8})\n",
    "    return top20\n",
    "\n",
    "top20s = tuple(\n",
    "    get_top20(typing.cast(fastf1_events.Event, race_weekend))\n",
    "    for _, race_weekend in schedule.iterrows()\n",
    ")\n",
    "display(hide_index(top20s[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "def driver_sentiment(comments, driver_list):\n",
    "    model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    results = {driver: {\"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0, \"count\": 0} for driver in driver_list}\n",
    "\n",
    "    for comment in comments:\n",
    "        found_drivers = [driver for driver in driver_list if driver in comment]\n",
    "        \n",
    "        for aspect in found_drivers:\n",
    "            inputs = tokenizer(comment, aspect, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            scores = outputs.logits[0].cpu().numpy()\n",
    "            probabilities = softmax(scores)\n",
    "\n",
    "            results[aspect][\"positive\"] += probabilities[2]\n",
    "            results[aspect][\"neutral\"] += probabilities[1]\n",
    "            results[aspect][\"negative\"] += probabilities[0]\n",
    "            results[aspect][\"count\"] += 1\n",
    "\n",
    "    for driver, sentiment in results.items():\n",
    "        if sentiment[\"count\"] > 0:\n",
    "            sentiment[\"positive\"] /= sentiment[\"count\"]\n",
    "            sentiment[\"neutral\"] /= sentiment[\"count\"]\n",
    "            sentiment[\"negative\"] /= sentiment[\"count\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "prediction_posts_df = ['Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, Max Verstappen will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!']\n",
    "driver_list = ['Carlos Sainz', 'Max Verstappen']\n",
    "\n",
    "results = driver_sentiment(prediction_posts_df, driver_list)\n",
    "\n",
    "for driver, sentiment in results.items():\n",
    "    if sentiment[\"count\"] > 0:\n",
    "        print(f\"{driver}: [Positive: {sentiment['positive']:.4f}, Neutral: {sentiment['neutral']:.4f}, Negative: {sentiment['negative']:.4f}]\")\n",
    "    else:\n",
    "        print(f\"{driver}: No mentions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_scores(results):\n",
    "    final_scores = []\n",
    "\n",
    "    for driver, sentiment in results.items():\n",
    "        if sentiment[\"count\"] > 0:\n",
    "            sentiment_score = (sentiment[\"positive\"] - sentiment[\"negative\"])\n",
    "            final_scores.append((driver.title(), sentiment_score))\n",
    "\n",
    "    # Sort drivers by positive - negative score (descending order)\n",
    "    final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "# Print sorted results\n",
    "scores = final_scores(results)\n",
    "\n",
    "print(\"Drivers ranked by (positive - negative score):\")\n",
    "for driver, score in scores:\n",
    "    print(f\"{driver}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(n_event, final_scores, n_events=5, historical_score_contribution=0.4):\n",
    "    #func to import historical data for this race\n",
    "    historical_data = get_top20(n_event)\n",
    "    historical_scores = {row[\"DriverFullName\"]: 0 for _, row in historical_data.iterrows()}\n",
    "\n",
    "    for i in range(n_events):\n",
    "        #func to import historical data for one of the last 5 races\n",
    "        historical_data = get_top20(n_event - (i+1))\n",
    "\n",
    "        for _, row in historical_data.iterrows():\n",
    "            historical_scores[row[\"DriverFullName\"]] += 1 - ((row[\"Pos\"] - 1) / 19) * 2\n",
    "\n",
    "    for driver, score in historical_scores.items():\n",
    "        historical_scores[driver] = score / n_events\n",
    "\n",
    "    final_scores_dict = dict(final_scores)\n",
    "\n",
    "    final_prediction = []\n",
    "    for driver, historical_score in historical_scores.items():\n",
    "        if driver in final_scores_dict:\n",
    "            score = final_scores_dict[driver]\n",
    "            \n",
    "            combined_score = (1 - historical_score_contribution) * score + historical_score_contribution * historical_score\n",
    "            final_prediction.append((driver, combined_score))\n",
    "        else:\n",
    "            final_prediction.append((driver, historical_score))\n",
    "\n",
    "    final_prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return final_prediction\n",
    "\n",
    "# final_prediction = prediction(16, scores, n_events=5, historical_score_contribution=0.4)\n",
    "# pos = 0\n",
    "# for driver, score in final_prediction:\n",
    "#     pos += 1\n",
    "#     print(f\"{driver} finishes in position:{pos}      {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"C:\\\\cache\"\n",
    "from gliner import GLiNER\n",
    "\n",
    "gliner_pickle_path = config.DATA_DIR / '.cache' / 'gliner_model.pkl'\n",
    "gliner_pickle_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "use_cache = True\n",
    "\n",
    "if use_cache:\n",
    "    if not gliner_pickle_path.exists():\n",
    "        gliner_model = GLiNER.from_pretrained('urchade/gliner_medium-v2.1')\n",
    "\n",
    "        with open(gliner_pickle_path, 'wb') as file:\n",
    "            pickle.dump(gliner_model, file)\n",
    "    else:\n",
    "        with open(gliner_pickle_path, 'rb') as file:\n",
    "            gliner_model = pickle.load(file)\n",
    "else:\n",
    "    gliner_model = GLiNER.from_pretrained('urchade/gliner_medium-v2.1')\n",
    "\n",
    "gliner_model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = 'Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, verstappening will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!'\n",
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    doc = nlp(text)\n",
    "    df = pd.DataFrame({'text': tuple(sentence.text for sentence in doc.sents)})\n",
    "else:\n",
    "    df = load_f1_df(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with display_full_dataframe():\n",
    "    display(df)\n",
    "\n",
    "def has_prediction(post_text: str, threshold: float = 0.45) -> bool:\n",
    "    doc = nlp(post_text)\n",
    "\n",
    "    # TODO: does GLiNER's performance improve with more context? if yes, refactor to chunking instead of going over each sentence individually\n",
    "    for sentence in doc.sents:\n",
    "        # TODO: for some reason, if you include only 'position', the predictions are far worse than with 'driver' included\n",
    "        entities = gliner_model.predict_entities(sentence.text, ('driver', 'position',), threshold=threshold) # TODO: very low threshold\n",
    "        position_entities = tuple(entity for entity in entities if entity['label'] == 'position')\n",
    "\n",
    "        if debug:\n",
    "            print(position_entities)\n",
    "            print(tuple(position['text'] for position in position_entities))\n",
    "\n",
    "        if len(position_entities) != 0:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "predictions_df = df[df['text'].apply(has_prediction)]\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, verstappening will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!'\n",
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    doc = nlp(text)\n",
    "    df = pd.DataFrame({'text': tuple(sentence.text for sentence in doc.sents)})\n",
    "else:\n",
    "    df = load_f1_df(10)\n",
    "\n",
    "# with display_full_dataframe():\n",
    "#     display(hide_index(df.head()))\n",
    "\n",
    "df['text'] = df['text'].apply(preprocessing.correct_spelling_in_text_spacy)\n",
    "df = df[df['text'].apply(has_prediction)]\n",
    "\n",
    "for index, race_weekend in schedule.iterrows():\n",
    "    pred_comments = has_prediction(post, threshold=0.01)\n",
    "    sentiment = driver_sentiment(pred_comments, driver_list)\n",
    "    score = final_scores(sentiment)\n",
    "    pred = prediction(race_weekend, final_scores, n_events=5, historical_score_contribution=0.4)\n",
    "    print(pred)\n",
    "\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
