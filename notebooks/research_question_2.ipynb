{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Selected GPU: NVIDIA GeForce GTX 1080 Ti (device_id=0)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "from collections.abc import Generator, Callable\n",
    "import typing\n",
    "from typing import Any, TypeAlias\n",
    "import numpy as np\n",
    "from contextlib import contextmanager\n",
    "from functools import partial, reduce\n",
    "import re\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from IPython.display import (\n",
    "    display, # type: ignore[reportUnknownVariableType]\n",
    "    Markdown,\n",
    ")\n",
    "import importlib\n",
    "import spacy\n",
    "\n",
    "from config.fastf1 import fastf1\n",
    "import fastf1.events as fastf1_events\n",
    "from config import config\n",
    "importlib.reload(config);\n",
    "from src.data.loader import stream_ndjson, load_submissions_df, load_comments_df\n",
    "import src.data.preprocessing as preprocessing\n",
    "importlib.reload(preprocessing);\n",
    "import src.data.constants as dataset_constants\n",
    "import src.utils\n",
    "importlib.reload(src.utils);\n",
    "from src.utils import (\n",
    "    temporary_pandas_options,\n",
    "    display_full_dataframe,\n",
    "    hide_index,\n",
    "    compose,\n",
    ")\n",
    "from src import utils\n",
    "utils.set_random_seeds()\n",
    "\n",
    "import logging\n",
    "logging.getLogger('fastf1').setLevel(logging.WARNING)\n",
    "\n",
    "DEVICE = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_f1_df(limit: int | None = None, in_place: bool = True) -> pd.DataFrame:\n",
    "    ndjson_streamer = partial(stream_ndjson, limit=limit)\n",
    "\n",
    "    return preprocessing.concatenate_submissions_and_comments(\n",
    "        submissions_df=load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, ndjson_streamer),\n",
    "        comments_df=load_comments_df(dataset_constants.RawFile.FORMULA1_COMMENTS, ndjson_streamer),\n",
    "        in_place=in_place,\n",
    "    )\n",
    "\n",
    "def load_f15_df(limit: int | None = None, in_place: bool = True) -> pd.DataFrame:\n",
    "    ndjson_streamer = partial(stream_ndjson, limit=limit)\n",
    "\n",
    "    return preprocessing.concatenate_submissions_and_comments(\n",
    "        submissions_df=load_submissions_df(dataset_constants.RawFile.FORMULA1POINT5_SUBMISSIONS, ndjson_streamer),\n",
    "        comments_df=load_comments_df(dataset_constants.RawFile.FORMULA1POINT5_COMMENTS, ndjson_streamer),\n",
    "        in_place=in_place,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ndjson_streamer = partial(stream_ndjson, limit=100)\n",
    "f15_ndjson_streamer = partial(stream_ndjson, limit=100)\n",
    "\n",
    "f1_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1_SUBMISSIONS, f1_ndjson_streamer)\n",
    "f1_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1_COMMENTS, f1_ndjson_streamer)\n",
    "\n",
    "f15_submissions_df = load_submissions_df(dataset_constants.RawFile.FORMULA1POINT5_SUBMISSIONS, f15_ndjson_streamer)\n",
    "f15_comments_df = load_comments_df(dataset_constants.RawFile.FORMULA1POINT5_COMMENTS, f15_ndjson_streamer)\n",
    "\n",
    "f1_df = preprocessing.concatenate_submissions_and_comments(f1_submissions_df, f1_comments_df)\n",
    "f15_df = preprocessing.concatenate_submissions_and_comments(f15_submissions_df, f15_comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### r/formula1 submissions:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Discussion] Could professional ESports drivers drive a real F1 car? How realistic are the sims?</td>\n",
       "      <td>v2fbpg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 12:00:41</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Questions concerning Alonso's future</td>\n",
       "      <td>v2fh6w</td>\n",
       "      <td>Doomaster14</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-01 12:07:50</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts</td>\n",
       "      <td>v2fmeh</td>\n",
       "      <td>motorace_addict</td>\n",
       "      <td>1393</td>\n",
       "      <td>2022-06-01 12:15:14</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perez wins as Red Bull delivers race strategy blow to Ferrari - Mika Häkkinen’s thoughts on the Monaco Grand Prix</td>\n",
       "      <td>v2frea</td>\n",
       "      <td>MrTuxedo1</td>\n",
       "      <td>161</td>\n",
       "      <td>2022-06-01 12:23:16</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               title  \\\n",
       "0                   [Discussion] Could professional ESports drivers drive a real F1 car? How realistic are the sims?   \n",
       "1                                                                               Questions concerning Alonso's future   \n",
       "2  Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts   \n",
       "3  Perez wins as Red Bull delivers race strategy blow to Ferrari - Mika Häkkinen’s thoughts on the Monaco Grand Prix   \n",
       "\n",
       "       id           author  score         created_utc   selftext  gilded  \n",
       "0  v2fbpg        [deleted]      1 2022-06-01 12:00:41  [removed]       0  \n",
       "1  v2fh6w      Doomaster14      2 2022-06-01 12:07:50  [removed]       0  \n",
       "2  v2fmeh  motorace_addict   1393 2022-06-01 12:15:14                  0  \n",
       "3  v2frea        MrTuxedo1    161 2022-06-01 12:23:16                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### r/formula1 comments:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top part of the wing got shaken off in the tunnel.</td>\n",
       "      <td>iaq4tev</td>\n",
       "      <td>CowsWantToKillMe</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 00:00:57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's been the rumour with Mercedes lately cuz in previous seasons Bottas hasn't been the luckiest.</td>\n",
       "      <td>iaq4urr</td>\n",
       "      <td>doc_55lk</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-01 00:01:15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ah well, it's looking great already!</td>\n",
       "      <td>iaq4wpz</td>\n",
       "      <td>Organic-Measurement2</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-01 00:01:41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And Ferrari would get them all wrong.</td>\n",
       "      <td>iaq4x1h</td>\n",
       "      <td>not_right</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-06-01 00:01:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   body  \\\n",
       "0                                                    top part of the wing got shaken off in the tunnel.   \n",
       "1  That's been the rumour with Mercedes lately cuz in previous seasons Bottas hasn't been the luckiest.   \n",
       "2                                                                  Ah well, it's looking great already!   \n",
       "3                                                                 And Ferrari would get them all wrong.   \n",
       "\n",
       "        id                author  score         created_utc  gilded  \n",
       "0  iaq4tev      CowsWantToKillMe      1 2022-06-01 00:00:57       0  \n",
       "1  iaq4urr              doc_55lk      0 2022-06-01 00:01:15       0  \n",
       "2  iaq4wpz  Organic-Measurement2      3 2022-06-01 00:01:41       0  \n",
       "3  iaq4x1h             not_right     10 2022-06-01 00:01:46       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### r/formula1point5 submissions:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Formula 1 - Hakkinen vs Schumacher - Spa-Francorchamps 2000</td>\n",
       "      <td>v6qyud</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-07 09:21:41</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Formula 1 2003 - Rd 2 - Malaysian Grand Prix [Highlights] - Kimi Raikkonen Maiden Win</td>\n",
       "      <td>v6viae</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-07 13:26:25</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Formula 1 2003 - Rd 9 - European Grand Prix (Nurburgring) [Highlights]</td>\n",
       "      <td>v8bwj6</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-09 08:12:22</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Bull drivers free to fight each other</td>\n",
       "      <td>v8f1dk</td>\n",
       "      <td>ms_creativity</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-09 11:48:11</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   title  \\\n",
       "0                            Formula 1 - Hakkinen vs Schumacher - Spa-Francorchamps 2000   \n",
       "1  Formula 1 2003 - Rd 2 - Malaysian Grand Prix [Highlights] - Kimi Raikkonen Maiden Win   \n",
       "2                 Formula 1 2003 - Rd 9 - European Grand Prix (Nurburgring) [Highlights]   \n",
       "3                                              Red Bull drivers free to fight each other   \n",
       "\n",
       "       id         author  score         created_utc selftext  gilded  \n",
       "0  v6qyud   orfeomclaren      1 2022-06-07 09:21:41                0  \n",
       "1  v6viae   orfeomclaren      1 2022-06-07 13:26:25                0  \n",
       "2  v8bwj6   orfeomclaren      1 2022-06-09 08:12:22                0  \n",
       "3  v8f1dk  ms_creativity      1 2022-06-09 11:48:11                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### r/formula1point5 comments:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your team name please?</td>\n",
       "      <td>iaqwofj</td>\n",
       "      <td>debrek</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-01 03:50:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's lazily named team F1.5 and my name there is the same as my username here (Ignis Vizsla), I'm 34th on the leaderboard there for reference</td>\n",
       "      <td>iar7xgu</td>\n",
       "      <td>IgnisVizsla</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-01 05:54:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had removed you as I thought you were inactive since you had a number of teams with an invalid team. I re-added you to the list.</td>\n",
       "      <td>iar9z0m</td>\n",
       "      <td>debrek</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-01 06:20:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah that's my fault, I forgot to update my team after the rules changed as I always remembered only after quali and that was too late, I finally changed before Monaco though</td>\n",
       "      <td>iarc3x7</td>\n",
       "      <td>IgnisVizsla</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-01 06:49:13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                             body  \\\n",
       "0                                                                                                                                                  What is your team name please?   \n",
       "1                                   It's lazily named team F1.5 and my name there is the same as my username here (Ignis Vizsla), I'm 34th on the leaderboard there for reference   \n",
       "2                                              I had removed you as I thought you were inactive since you had a number of teams with an invalid team. I re-added you to the list.   \n",
       "3  Yeah that's my fault, I forgot to update my team after the rules changed as I always remembered only after quali and that was too late, I finally changed before Monaco though   \n",
       "\n",
       "        id       author  score         created_utc  gilded  \n",
       "0  iaqwofj       debrek      3 2022-06-01 03:50:49       0  \n",
       "1  iar7xgu  IgnisVizsla      2 2022-06-01 05:54:28       0  \n",
       "2  iar9z0m       debrek      3 2022-06-01 06:20:29       0  \n",
       "3  iarc3x7  IgnisVizsla      3 2022-06-01 06:49:13       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 submissions:'), f1_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1 comments:'), f1_comments_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 submissions:'), f15_submissions_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 comments:'), f15_comments_df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### r/formula1 posts:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2fbpg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01 12:00:41</td>\n",
       "      <td>0</td>\n",
       "      <td>[Discussion] Could professional ESports drivers drive a real F1 car? How realistic are the sims? [removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2fh6w</td>\n",
       "      <td>Doomaster14</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-01 12:07:50</td>\n",
       "      <td>0</td>\n",
       "      <td>Questions concerning Alonso's future. [removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2fmeh</td>\n",
       "      <td>motorace_addict</td>\n",
       "      <td>1393</td>\n",
       "      <td>2022-06-01 12:15:14</td>\n",
       "      <td>0</td>\n",
       "      <td>Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id           author  score         created_utc  gilded  \\\n",
       "0  v2fbpg        [deleted]      1 2022-06-01 12:00:41       0   \n",
       "1  v2fh6w      Doomaster14      2 2022-06-01 12:07:50       0   \n",
       "2  v2fmeh  motorace_addict   1393 2022-06-01 12:15:14       0   \n",
       "\n",
       "                                                                                                                  text  \n",
       "0           [Discussion] Could professional ESports drivers drive a real F1 car? How realistic are the sims? [removed]  \n",
       "1                                                                      Questions concerning Alonso's future. [removed]  \n",
       "2  Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts.   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### r/formula1point5 posts:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v6qyud</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-07 09:21:41</td>\n",
       "      <td>0</td>\n",
       "      <td>Formula 1 - Hakkinen vs Schumacher - Spa-Francorchamps 2000.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v6viae</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-07 13:26:25</td>\n",
       "      <td>0</td>\n",
       "      <td>Formula 1 2003 - Rd 2 - Malaysian Grand Prix [Highlights] - Kimi Raikkonen Maiden Win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v8bwj6</td>\n",
       "      <td>orfeomclaren</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-09 08:12:22</td>\n",
       "      <td>0</td>\n",
       "      <td>Formula 1 2003 - Rd 9 - European Grand Prix (Nurburgring) [Highlights]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        author  score         created_utc  gilded  \\\n",
       "0  v6qyud  orfeomclaren      1 2022-06-07 09:21:41       0   \n",
       "1  v6viae  orfeomclaren      1 2022-06-07 13:26:25       0   \n",
       "2  v8bwj6  orfeomclaren      1 2022-06-09 08:12:22       0   \n",
       "\n",
       "                                                                                      text  \n",
       "0                            Formula 1 - Hakkinen vs Schumacher - Spa-Francorchamps 2000.   \n",
       "1  Formula 1 2003 - Rd 2 - Malaysian Grand Prix [Highlights] - Kimi Raikkonen Maiden Win.   \n",
       "2                  Formula 1 2003 - Rd 9 - European Grand Prix (Nurburgring) [Highlights]   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(Markdown('### r/formula1 posts:'), f1_df.head(n))\n",
    "    display(Markdown('### r/formula1point5 posts:'), f15_df.head(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Rule-Based Prediction Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastf1 historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoundNumber</th>\n",
       "      <th>Country</th>\n",
       "      <th>Location</th>\n",
       "      <th>OfficialEventName</th>\n",
       "      <th>EventDate</th>\n",
       "      <th>EventName</th>\n",
       "      <th>EventFormat</th>\n",
       "      <th>Session1</th>\n",
       "      <th>Session1Date</th>\n",
       "      <th>Session1DateUtc</th>\n",
       "      <th>Session2</th>\n",
       "      <th>Session2Date</th>\n",
       "      <th>Session2DateUtc</th>\n",
       "      <th>Session3</th>\n",
       "      <th>Session3Date</th>\n",
       "      <th>Session3DateUtc</th>\n",
       "      <th>Session4</th>\n",
       "      <th>Session4Date</th>\n",
       "      <th>Session4DateUtc</th>\n",
       "      <th>Session5</th>\n",
       "      <th>Session5Date</th>\n",
       "      <th>Session5DateUtc</th>\n",
       "      <th>F1ApiSupport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>United States</td>\n",
       "      <td>Austin</td>\n",
       "      <td>FORMULA 1 ARAMCO UNITED STATES GRAND PRIX 2022</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Practice 1</td>\n",
       "      <td>2022-10-21 14:00:00-05:00</td>\n",
       "      <td>2022-10-21 19:00:00</td>\n",
       "      <td>Practice 2</td>\n",
       "      <td>2022-10-21 17:00:00-05:00</td>\n",
       "      <td>2022-10-21 22:00:00</td>\n",
       "      <td>Practice 3</td>\n",
       "      <td>2022-10-22 14:00:00-05:00</td>\n",
       "      <td>2022-10-22 19:00:00</td>\n",
       "      <td>Qualifying</td>\n",
       "      <td>2022-10-22 17:00:00-05:00</td>\n",
       "      <td>2022-10-22 22:00:00</td>\n",
       "      <td>Race</td>\n",
       "      <td>2022-10-23 14:00:00-05:00</td>\n",
       "      <td>2022-10-23 19:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexico City</td>\n",
       "      <td>FORMULA 1 HEINEKEN GRAN PREMIO DE LA CIUDAD DE MÉXICO 2022</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>Mexico City Grand Prix</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Practice 1</td>\n",
       "      <td>2022-10-28 13:00:00-06:00</td>\n",
       "      <td>2022-10-28 19:00:00</td>\n",
       "      <td>Practice 2</td>\n",
       "      <td>2022-10-28 16:00:00-06:00</td>\n",
       "      <td>2022-10-28 22:00:00</td>\n",
       "      <td>Practice 3</td>\n",
       "      <td>2022-10-29 12:00:00-06:00</td>\n",
       "      <td>2022-10-29 18:00:00</td>\n",
       "      <td>Qualifying</td>\n",
       "      <td>2022-10-29 15:00:00-06:00</td>\n",
       "      <td>2022-10-29 21:00:00</td>\n",
       "      <td>Race</td>\n",
       "      <td>2022-10-30 14:00:00-06:00</td>\n",
       "      <td>2022-10-30 20:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>Yas Island</td>\n",
       "      <td>FORMULA 1 ETIHAD AIRWAYS ABU DHABI GRAND PRIX 2022</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>conventional</td>\n",
       "      <td>Practice 1</td>\n",
       "      <td>2022-11-18 14:00:00+04:00</td>\n",
       "      <td>2022-11-18 10:00:00</td>\n",
       "      <td>Practice 2</td>\n",
       "      <td>2022-11-18 17:00:00+04:00</td>\n",
       "      <td>2022-11-18 13:00:00</td>\n",
       "      <td>Practice 3</td>\n",
       "      <td>2022-11-19 14:30:00+04:00</td>\n",
       "      <td>2022-11-19 10:30:00</td>\n",
       "      <td>Qualifying</td>\n",
       "      <td>2022-11-19 18:00:00+04:00</td>\n",
       "      <td>2022-11-19 14:00:00</td>\n",
       "      <td>Race</td>\n",
       "      <td>2022-11-20 17:00:00+04:00</td>\n",
       "      <td>2022-11-20 13:00:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RoundNumber        Country     Location  \\\n",
       "20           19  United States       Austin   \n",
       "21           20         Mexico  Mexico City   \n",
       "23           22      Abu Dhabi   Yas Island   \n",
       "\n",
       "                                             OfficialEventName  EventDate  \\\n",
       "20              FORMULA 1 ARAMCO UNITED STATES GRAND PRIX 2022 2022-10-23   \n",
       "21  FORMULA 1 HEINEKEN GRAN PREMIO DE LA CIUDAD DE MÉXICO 2022 2022-10-30   \n",
       "23          FORMULA 1 ETIHAD AIRWAYS ABU DHABI GRAND PRIX 2022 2022-11-20   \n",
       "\n",
       "                   EventName   EventFormat    Session1  \\\n",
       "20  United States Grand Prix  conventional  Practice 1   \n",
       "21    Mexico City Grand Prix  conventional  Practice 1   \n",
       "23      Abu Dhabi Grand Prix  conventional  Practice 1   \n",
       "\n",
       "                 Session1Date     Session1DateUtc    Session2  \\\n",
       "20  2022-10-21 14:00:00-05:00 2022-10-21 19:00:00  Practice 2   \n",
       "21  2022-10-28 13:00:00-06:00 2022-10-28 19:00:00  Practice 2   \n",
       "23  2022-11-18 14:00:00+04:00 2022-11-18 10:00:00  Practice 2   \n",
       "\n",
       "                 Session2Date     Session2DateUtc    Session3  \\\n",
       "20  2022-10-21 17:00:00-05:00 2022-10-21 22:00:00  Practice 3   \n",
       "21  2022-10-28 16:00:00-06:00 2022-10-28 22:00:00  Practice 3   \n",
       "23  2022-11-18 17:00:00+04:00 2022-11-18 13:00:00  Practice 3   \n",
       "\n",
       "                 Session3Date     Session3DateUtc    Session4  \\\n",
       "20  2022-10-22 14:00:00-05:00 2022-10-22 19:00:00  Qualifying   \n",
       "21  2022-10-29 12:00:00-06:00 2022-10-29 18:00:00  Qualifying   \n",
       "23  2022-11-19 14:30:00+04:00 2022-11-19 10:30:00  Qualifying   \n",
       "\n",
       "                 Session4Date     Session4DateUtc Session5  \\\n",
       "20  2022-10-22 17:00:00-05:00 2022-10-22 22:00:00     Race   \n",
       "21  2022-10-29 15:00:00-06:00 2022-10-29 21:00:00     Race   \n",
       "23  2022-11-19 18:00:00+04:00 2022-11-19 14:00:00     Race   \n",
       "\n",
       "                 Session5Date     Session5DateUtc  F1ApiSupport  \n",
       "20  2022-10-23 14:00:00-05:00 2022-10-23 19:00:00          True  \n",
       "21  2022-10-30 14:00:00-06:00 2022-10-30 20:00:00          True  \n",
       "23  2022-11-20 17:00:00+04:00 2022-11-20 13:00:00          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_schedule = fastf1.get_event_schedule(dataset_constants.YEAR)\n",
    "schedule = typing.cast(\n",
    "    fastf1_events.EventSchedule,\n",
    "    full_schedule[\n",
    "        (full_schedule['EventDate'] >= dataset_constants.START_DATE) &\n",
    "        (full_schedule['EventDate'] <= dataset_constants.END_DATE) &\n",
    "        (full_schedule['EventFormat'] == 'conventional') # TODO: Skip sprint weekends for now. Also include sprint weekends later\n",
    "    ],\n",
    ")\n",
    "\n",
    "with display_full_dataframe():\n",
    "    display(schedule.iloc[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0b264\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0b264_level0_col0\" class=\"col_heading level0 col0\" >FullName</th>\n",
       "      <th id=\"T_0b264_level0_col1\" class=\"col_heading level0 col1\" >Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row0_col0\" class=\"data row0 col0\" >Max Verstappen</td>\n",
       "      <td id=\"T_0b264_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row1_col0\" class=\"data row1 col0\" >Charles Leclerc</td>\n",
       "      <td id=\"T_0b264_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row2_col0\" class=\"data row2 col0\" >Sergio Perez</td>\n",
       "      <td id=\"T_0b264_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row3_col0\" class=\"data row3 col0\" >Carlos Sainz</td>\n",
       "      <td id=\"T_0b264_row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row4_col0\" class=\"data row4 col0\" >George Russell</td>\n",
       "      <td id=\"T_0b264_row4_col1\" class=\"data row4 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row5_col0\" class=\"data row5 col0\" >Lando Norris</td>\n",
       "      <td id=\"T_0b264_row5_col1\" class=\"data row5 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row6_col0\" class=\"data row6 col0\" >Esteban Ocon</td>\n",
       "      <td id=\"T_0b264_row6_col1\" class=\"data row6 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row7_col0\" class=\"data row7 col0\" >Lance Stroll</td>\n",
       "      <td id=\"T_0b264_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row8_col0\" class=\"data row8 col0\" >Daniel Ricciardo</td>\n",
       "      <td id=\"T_0b264_row8_col1\" class=\"data row8 col1\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row9_col0\" class=\"data row9 col0\" >Sebastian Vettel</td>\n",
       "      <td id=\"T_0b264_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row10_col0\" class=\"data row10 col0\" >Yuki Tsunoda</td>\n",
       "      <td id=\"T_0b264_row10_col1\" class=\"data row10 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row11_col0\" class=\"data row11 col0\" >Guanyu Zhou</td>\n",
       "      <td id=\"T_0b264_row11_col1\" class=\"data row11 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row12_col0\" class=\"data row12 col0\" >Alexander Albon</td>\n",
       "      <td id=\"T_0b264_row12_col1\" class=\"data row12 col1\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row13_col0\" class=\"data row13 col0\" >Pierre Gasly</td>\n",
       "      <td id=\"T_0b264_row13_col1\" class=\"data row13 col1\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row14_col0\" class=\"data row14 col0\" >Valtteri Bottas</td>\n",
       "      <td id=\"T_0b264_row14_col1\" class=\"data row14 col1\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row15_col0\" class=\"data row15 col0\" >Mick Schumacher</td>\n",
       "      <td id=\"T_0b264_row15_col1\" class=\"data row15 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row16_col0\" class=\"data row16 col0\" >Kevin Magnussen</td>\n",
       "      <td id=\"T_0b264_row16_col1\" class=\"data row16 col1\" >17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row17_col0\" class=\"data row17 col0\" >Lewis Hamilton</td>\n",
       "      <td id=\"T_0b264_row17_col1\" class=\"data row17 col1\" >18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row18_col0\" class=\"data row18 col0\" >Nicholas Latifi</td>\n",
       "      <td id=\"T_0b264_row18_col1\" class=\"data row18 col1\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0b264_row19_col0\" class=\"data row19 col0\" >Fernando Alonso</td>\n",
       "      <td id=\"T_0b264_row19_col1\" class=\"data row19 col1\" >20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e5f852be90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posts_df = f1_df\n",
    "race_weekend = schedule.iloc[-1]\n",
    "first_post_at = typing.cast(dt.datetime, race_weekend['Session1DateUtc']) - dt.timedelta(days=1)\n",
    "last_post_at = typing.cast(dt.datetime, race_weekend['Session5DateUtc'])\n",
    "posts_df = posts_df[\n",
    "    (posts_df['created_utc'] >= first_post_at) &\n",
    "    (posts_df['created_utc'] <= last_post_at)\n",
    "]\n",
    "\n",
    "def get_top20(race_weekend: fastf1_events.Event) -> pd.DataFrame:\n",
    "    race_session = race_weekend.get_session('Race')\n",
    "    race_session.load(laps=False, telemetry=False, weather=False, messages=False)\n",
    "    top20 = race_session.results[['FullName', 'Position']].astype({'Position': np.uint8})\n",
    "    return top20\n",
    "\n",
    "top20s = tuple(\n",
    "    get_top20(typing.cast(fastf1_events.Event, race_weekend))\n",
    "    for _, race_weekend in schedule.iterrows()\n",
    ")\n",
    "display(hide_index(top20s[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kevin magnussen: No mentions found.\n",
      "charles leclerc: No mentions found.\n",
      "daniel ricciardo: No mentions found.\n",
      "max verstappen: No mentions found.\n",
      "fernando alonso: No mentions found.\n",
      "zhou guanyu: No mentions found.\n",
      "liam lawson: No mentions found.\n",
      "george russell: No mentions found.\n",
      "lando norris: No mentions found.\n",
      "carlos sainz: No mentions found.\n",
      "oscar piastri: No mentions found.\n",
      "nyck de vries: No mentions found.\n",
      "pierre gasly: No mentions found.\n",
      "lance stroll: No mentions found.\n",
      "yuki tsunoda: No mentions found.\n",
      "esteban ocon: No mentions found.\n",
      "alexander albon: No mentions found.\n",
      "logan sargeant: No mentions found.\n",
      "valtteri bottas: No mentions found.\n",
      "mick schumacher: No mentions found.\n",
      "lewis hamilton: No mentions found.\n",
      "nicholas latifi: No mentions found.\n",
      "nico hulkenberg: No mentions found.\n",
      "sebastian vettel: No mentions found.\n",
      "sergio perez: No mentions found.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "def driver_sentiment(comments, driver_list):\n",
    "    model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    results = {driver: {\"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0, \"count\": 0} for driver in driver_list}\n",
    "\n",
    "    for comment in comments:\n",
    "        found_drivers = [driver for driver in driver_list if driver in comment]\n",
    "        \n",
    "        for aspect in found_drivers:\n",
    "            inputs = tokenizer(comment, aspect, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            \n",
    "            scores = outputs.logits[0].cpu().numpy()\n",
    "            probabilities = softmax(scores)\n",
    "\n",
    "            results[aspect][\"positive\"] += probabilities[2]\n",
    "            results[aspect][\"neutral\"] += probabilities[1]\n",
    "            results[aspect][\"negative\"] += probabilities[0]\n",
    "            results[aspect][\"count\"] += 1\n",
    "\n",
    "    for driver, sentiment in results.items():\n",
    "        if sentiment[\"count\"] > 0:\n",
    "            sentiment[\"positive\"] /= sentiment[\"count\"]\n",
    "            sentiment[\"neutral\"] /= sentiment[\"count\"]\n",
    "            sentiment[\"negative\"] /= sentiment[\"count\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "prediction_posts_df = ['Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, Max Verstappen will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!']\n",
    "driver_list = ['Carlos Sainz', 'Max Verstappen']\n",
    "\n",
    "F1_names= {\n",
    "    'max verstappen',\n",
    "    'charles leclerc',\n",
    "    'sergio perez',\n",
    "    'george russell',\n",
    "    'carlos sainz',\n",
    "    'lewis hamilton',\n",
    "    'lando norris',\n",
    "    'esteban ocon',\n",
    "    'fernando alonso',\n",
    "    'valtteri bottas',\n",
    "    'daniel ricciardo',\n",
    "    'sebastian vettel',\n",
    "    'kevin magnussen',\n",
    "    'pierre gasly',\n",
    "    'lance stroll',\n",
    "    'mick schumacher',\n",
    "    'yuki tsunoda',\n",
    "    'zhou guanyu',\n",
    "    'alexander albon',\n",
    "    'nicholas latifi',\n",
    "    'nyck de vries',\n",
    "    'nico hulkenberg',\n",
    "    'oscar piastri',\n",
    "    'liam lawson',\n",
    "    'logan sargeant'\n",
    "}\n",
    "\n",
    "\n",
    "results = driver_sentiment(load_f1_df(1000)[\"text\"], F1_names)\n",
    "\n",
    "for driver, sentiment in results.items():\n",
    "    if sentiment[\"count\"] > 0:\n",
    "        print(f\"{driver}: [Positive: {sentiment['positive']:.4f}, Neutral: {sentiment['neutral']:.4f}, Negative: {sentiment['negative']:.4f}]\")\n",
    "    else:\n",
    "        print(f\"{driver}: No mentions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers ranked by (positive - negative score):\n"
     ]
    }
   ],
   "source": [
    "def final_scores(results):\n",
    "    final_scores = []\n",
    "\n",
    "    for driver, sentiment in results.items():\n",
    "        if sentiment[\"count\"] > 0:\n",
    "            sentiment_score = (sentiment[\"positive\"] - sentiment[\"negative\"])\n",
    "            final_scores.append((driver.title(), sentiment_score))\n",
    "\n",
    "    # Sort drivers by positive - negative score (descending order)\n",
    "    final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "# Print sorted results\n",
    "scores = final_scores(results)\n",
    "\n",
    "print(\"Drivers ranked by (positive - negative score):\")\n",
    "for driver, score in scores:\n",
    "    print(f\"{driver}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(n_event, final_scores, n_events=5, historical_score_contribution=0.4):\n",
    "    #func to import historical data for this race\n",
    "    historical_data = get_top20(n_event)\n",
    "    historical_scores = {row[\"DriverFullName\"]: 0 for _, row in historical_data.iterrows()}\n",
    "\n",
    "    for i in range(n_events):\n",
    "        #func to import historical data for one of the last 5 races\n",
    "        historical_data = get_top20(n_event - (i+1))\n",
    "\n",
    "        for _, row in historical_data.iterrows():\n",
    "            historical_scores[row[\"DriverFullName\"]] += 1 - ((row[\"Pos\"] - 1) / 19) * 2\n",
    "\n",
    "    for driver, score in historical_scores.items():\n",
    "        historical_scores[driver] = score / n_events\n",
    "\n",
    "    final_scores_dict = dict(final_scores)\n",
    "\n",
    "    final_prediction = []\n",
    "    for driver, historical_score in historical_scores.items():\n",
    "        if driver in final_scores_dict:\n",
    "            score = final_scores_dict[driver]\n",
    "            \n",
    "            combined_score = (1 - historical_score_contribution) * score + historical_score_contribution * historical_score\n",
    "            final_prediction.append((driver, combined_score))\n",
    "        else:\n",
    "            final_prediction.append((driver, historical_score))\n",
    "\n",
    "    final_prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return final_prediction\n",
    "\n",
    "# final_prediction = prediction(16, scores, n_events=5, historical_score_contribution=0.4)\n",
    "# pos = 0\n",
    "# for driver, score in final_prediction:\n",
    "#     pos += 1\n",
    "#     print(f\"{driver} finishes in position:{pos}      {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe096fc254f48188ffc60370bdd581c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"C:\\\\cache\"\n",
    "from gliner import GLiNER\n",
    "\n",
    "gliner_pickle_path = config.DATA_DIR / '.cache' / 'gliner_model.pkl'\n",
    "gliner_pickle_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "use_cache = False\n",
    "\n",
    "if use_cache:\n",
    "    if not gliner_pickle_path.exists():\n",
    "        gliner_model = GLiNER.from_pretrained('urchade/gliner_medium-v2.1')\n",
    "\n",
    "        with open(gliner_pickle_path, 'wb') as file:\n",
    "            pickle.dump(gliner_model, file)\n",
    "    else:\n",
    "        with open(gliner_pickle_path, 'rb') as file:\n",
    "            gliner_model = pickle.load(file)\n",
    "else:\n",
    "    gliner_model = GLiNER.from_pretrained('urchade/gliner_medium-v2.1')\n",
    "\n",
    "gliner_model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gliner.model.GLiNER'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gliner_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = 'Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, verstappening will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!'\n",
    "debug = True\n",
    "\n",
    "if debug:\n",
    "    doc = nlp(text)\n",
    "    df = pd.DataFrame({'text': tuple(sentence.text for sentence in doc.sents)})\n",
    "else:\n",
    "    df = load_f1_df(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I disagree with you, verstappening will definitely finish first.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think BOT will finish behind NOR, who will probably finish 7th.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That's my opinion at least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I predict that the RedBulls with finish 1-2.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text\n",
       "0  Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow!\n",
       "1             I disagree with you, verstappening will definitely finish first.\n",
       "2            I think BOT will finish behind NOR, who will probably finish 7th.\n",
       "3                                                That's my opinion at least...\n",
       "4                                 I predict that the RedBulls with finish 1-2."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'start': 47, 'end': 52, 'text': 'top 3', 'label': 'position', 'score': 0.6188601851463318},)\n",
      "('top 3',)\n",
      "()\n",
      "()\n",
      "({'start': 61, 'end': 64, 'text': '7th', 'label': 'position', 'score': 0.8359587788581848},)\n",
      "('7th',)\n",
      "()\n",
      "()\n",
      "({'start': 40, 'end': 43, 'text': '1-2', 'label': 'position', 'score': 0.8649768829345703},)\n",
      "('1-2',)\n",
      "({'start': 65, 'end': 71, 'text': 'points', 'label': 'position', 'score': 0.5379745960235596},)\n",
      "('points',)\n",
      "({'start': 14, 'end': 20, 'text': 'podium', 'label': 'position', 'score': 0.6982569694519043}, {'start': 35, 'end': 41, 'text': 'points', 'label': 'position', 'score': 0.4657585620880127})\n",
      "('podium', 'points')\n",
      "()\n",
      "()\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think BOT will finish behind NOR, who will probably finish 7th.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I predict that the RedBulls with finish 1-2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nah, the Danish driver from Haas will almost certainly finish in points!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stroll on the podium and Vettel in points.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          text\n",
       "0  Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow!\n",
       "2            I think BOT will finish behind NOR, who will probably finish 7th.\n",
       "4                                 I predict that the RedBulls with finish 1-2.\n",
       "5     Nah, the Danish driver from Haas will almost certainly finish in points!\n",
       "6                                   Stroll on the podium and Vettel in points."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with display_full_dataframe():\n",
    "    display(df.head())\n",
    "\n",
    "def has_prediction(post_text: str, threshold: float = 0.45) -> bool:\n",
    "    # doc = nlp(post_text)\n",
    "\n",
    "    # TODO: does GLiNER's performance improve with more context? if yes, refactor to chunking instead of going over each sentence individually\n",
    "    # for sentence in doc.sents:\n",
    "    # TODO: for some reason, if you include only 'position', the predictions are far worse than with 'driver' included\n",
    "    with torch.no_grad():\n",
    "        entities = gliner_model.predict_entities(post_text, ('driver', 'position',), threshold=threshold) # TODO: very low threshold\n",
    "    position_entities = tuple(entity for entity in entities if entity['label'] == 'position')\n",
    "\n",
    "    if debug:\n",
    "        print(position_entities)\n",
    "        print(tuple(position['text'] for position in position_entities))\n",
    "\n",
    "    if len(position_entities) != 0:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "predictions_df = df[df['text'].apply(has_prediction)]\n",
    "print(len(predictions_df))\n",
    "with display_full_dataframe():\n",
    "    display(predictions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_prediction_dask(post_text):\n",
    "    return has_prediction(post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "({'start': 148, 'end': 158, 'text': 'rb juniors', 'label': 'position', 'score': 0.6453344821929932}, {'start': 194, 'end': 198, 'text': 'vips', 'label': 'position', 'score': 0.8511852622032166})\n",
      "('rb juniors', 'vips')\n",
      "({'start': 27, 'end': 32, 'text': 'poles', 'label': 'position', 'score': 0.5947211980819702},)\n",
      "('poles',)\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n",
      "({'start': 75, 'end': 85, 'text': 'head of F1', 'label': 'position', 'score': 0.8285242319107056},)\n",
      "('head of F1',)\n",
      "()\n",
      "()\n",
      "()\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "      <th>text</th>\n",
       "      <th>has_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2fmeh</td>\n",
       "      <td>motorace_addict</td>\n",
       "      <td>1393</td>\n",
       "      <td>2022-06-01 12:15:14</td>\n",
       "      <td>0</td>\n",
       "      <td>Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v2fv0f</td>\n",
       "      <td>jovanmilic97</td>\n",
       "      <td>451</td>\n",
       "      <td>2022-06-01 12:28:38</td>\n",
       "      <td>0</td>\n",
       "      <td>[Joe Saward] Sources saying that Peter Bayer has gone from his position as head of F1 at the FIA...checking now.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iaq4yx5</td>\n",
       "      <td>thetrueblue44</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-01 00:02:11</td>\n",
       "      <td>0</td>\n",
       "      <td>So far I think tsunoda has been better this year, even beating gasly a few times (and it’s only been 7 races!)\n",
       "\n",
       "Yeah I share the sentiment that the rb juniors aren’t up to grips yet, especially vips and hauger throwing away big points</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id           author  score         created_utc  gilded  \\\n",
       "2    v2fmeh  motorace_addict   1393 2022-06-01 12:15:14       0   \n",
       "5    v2fv0f     jovanmilic97    451 2022-06-01 12:28:38       0   \n",
       "14  iaq4yx5    thetrueblue44      2 2022-06-01 00:02:11       0   \n",
       "\n",
       "                                                                                                                                                                                                                                          text  \\\n",
       "2                                                                                                                          Verstappen now has as many poles as Leclerc - but six times as many wins | 2022 Monaco Grand Prix stats and facts.    \n",
       "5                                                                                                                            [Joe Saward] Sources saying that Peter Bayer has gone from his position as head of F1 at the FIA...checking now.    \n",
       "14  So far I think tsunoda has been better this year, even beating gasly a few times (and it’s only been 7 races!)\n",
       "\n",
       "Yeah I share the sentiment that the rb juniors aren’t up to grips yet, especially vips and hauger throwing away big points   \n",
       "\n",
       "    has_prediction  \n",
       "2             True  \n",
       "5             True  \n",
       "14            True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Convert the Pandas DataFrame to a Dask DataFrame\n",
    "dask_df = dd.from_pandas(load_f1_df(10), npartitions=16)  # Adjust the number of partitions as needed\n",
    "\n",
    "# Apply the function in parallel\n",
    "dask_df['has_prediction'] = dask_df['text'].map(has_prediction_dask, meta=('text', 'bool'))\n",
    "\n",
    "# Compute the result and convert back to a Pandas DataFrame\n",
    "result_df = dask_df[dask_df['has_prediction']].compute()\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "with display_full_dataframe():\n",
    "    display(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>v8ebwa</td>\n",
       "      <td>FormulaStatAnalysis</td>\n",
       "      <td>111</td>\n",
       "      <td>2022-06-09 11:05:19</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferrari vs Redbull Mini-sectors:Baku.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>v8ec2t</td>\n",
       "      <td>vedhavet</td>\n",
       "      <td>1070</td>\n",
       "      <td>2022-06-09 11:05:38</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mohammed Ben Sulayem] As a driver, I have alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>v8ec94</td>\n",
       "      <td>steen311</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-09 11:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>[Mohammed Ben Sulayem] As a driver, I have alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>v8edg8</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-06-09 11:08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>[Sky Sports F1] \"Everybody has the right to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>v8eh0a</td>\n",
       "      <td>FederalEngineer</td>\n",
       "      <td>1666</td>\n",
       "      <td>2022-06-09 11:14:22</td>\n",
       "      <td>0</td>\n",
       "      <td>Ferrari new mirrors.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               author  score         created_utc  gilded  \\\n",
       "1357  v8ebwa  FormulaStatAnalysis    111 2022-06-09 11:05:19       0   \n",
       "1358  v8ec2t             vedhavet   1070 2022-06-09 11:05:38       0   \n",
       "1359  v8ec94             steen311      0 2022-06-09 11:05:57       0   \n",
       "1360  v8edg8            [deleted]      9 2022-06-09 11:08:00       0   \n",
       "1361  v8eh0a      FederalEngineer   1666 2022-06-09 11:14:22       0   \n",
       "\n",
       "                                                   text  \n",
       "1357             Ferrari vs Redbull Mini-sectors:Baku.   \n",
       "1358  [Mohammed Ben Sulayem] As a driver, I have alw...  \n",
       "1359  [Mohammed Ben Sulayem] As a driver, I have alw...  \n",
       "1360  [Sky Sports F1] \"Everybody has the right to th...  \n",
       "1361                              Ferrari new mirrors.   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f32e0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f32e0_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_f32e0_level0_col1\" class=\"col_heading level0 col1\" >author</th>\n",
       "      <th id=\"T_f32e0_level0_col2\" class=\"col_heading level0 col2\" >score</th>\n",
       "      <th id=\"T_f32e0_level0_col3\" class=\"col_heading level0 col3\" >created_utc</th>\n",
       "      <th id=\"T_f32e0_level0_col4\" class=\"col_heading level0 col4\" >gilded</th>\n",
       "      <th id=\"T_f32e0_level0_col5\" class=\"col_heading level0 col5\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f32e0_row0_col0\" class=\"data row0 col0\" >v8ebwa</td>\n",
       "      <td id=\"T_f32e0_row0_col1\" class=\"data row0 col1\" >FormulaStatAnalysis</td>\n",
       "      <td id=\"T_f32e0_row0_col2\" class=\"data row0 col2\" >111</td>\n",
       "      <td id=\"T_f32e0_row0_col3\" class=\"data row0 col3\" >2022-06-09 11:05:19</td>\n",
       "      <td id=\"T_f32e0_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_f32e0_row0_col5\" class=\"data row0 col5\" >Ferrari vs Redbull Mini-sectors:Baku. </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f32e0_row1_col0\" class=\"data row1 col0\" >v8ec2t</td>\n",
       "      <td id=\"T_f32e0_row1_col1\" class=\"data row1 col1\" >vedhavet</td>\n",
       "      <td id=\"T_f32e0_row1_col2\" class=\"data row1 col2\" >1070</td>\n",
       "      <td id=\"T_f32e0_row1_col3\" class=\"data row1 col3\" >2022-06-09 11:05:38</td>\n",
       "      <td id=\"T_f32e0_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_f32e0_row1_col5\" class=\"data row1 col5\" >[Mohammed Ben Sulayem] As a driver, I have always believed in sport as a catalyst of progress in society. That is why promoting sustainability, diversity and inclusion is a key priority of my mandate. In the same way, I value the commitment of all drivers and champions for a better future. </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f32e0_row2_col0\" class=\"data row2 col0\" >v8ec94</td>\n",
       "      <td id=\"T_f32e0_row2_col1\" class=\"data row2 col1\" >steen311</td>\n",
       "      <td id=\"T_f32e0_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_f32e0_row2_col3\" class=\"data row2 col3\" >2022-06-09 11:05:57</td>\n",
       "      <td id=\"T_f32e0_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_f32e0_row2_col5\" class=\"data row2 col5\" >[Mohammed Ben Sulayem] As a driver, I have always believed in sport as a catalyst of progress in society. That is why promoting sustainability, diversity and inclusion is a key priority of my mandate. In the same way, I value the commitment of all drivers and champions for a better future. </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e5f85fe5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638.6211493 spell time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>gilded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>v8ebwa</td>\n",
       "      <td>FormulaStatAnalysis</td>\n",
       "      <td>111</td>\n",
       "      <td>2022-06-09 11:05:19</td>\n",
       "      <td>0</td>\n",
       "      <td>ferrari is bull mini-sectors:baku.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>v8ec2t</td>\n",
       "      <td>vedhavet</td>\n",
       "      <td>1070</td>\n",
       "      <td>2022-06-09 11:05:38</td>\n",
       "      <td>0</td>\n",
       "      <td>[mohammad men player] is a driver, a have alwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>v8ec94</td>\n",
       "      <td>steen311</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-09 11:05:57</td>\n",
       "      <td>0</td>\n",
       "      <td>[mohammad men player] is a driver, a have alwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>v8edg8</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-06-09 11:08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>[sky sports F1] \"everybody has ﻿the right to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>v8eh0a</td>\n",
       "      <td>FederalEngineer</td>\n",
       "      <td>1666</td>\n",
       "      <td>2022-06-09 11:14:22</td>\n",
       "      <td>0</td>\n",
       "      <td>ferrari new mirrors.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               author  score         created_utc  gilded  \\\n",
       "1357  v8ebwa  FormulaStatAnalysis    111 2022-06-09 11:05:19       0   \n",
       "1358  v8ec2t             vedhavet   1070 2022-06-09 11:05:38       0   \n",
       "1359  v8ec94             steen311      0 2022-06-09 11:05:57       0   \n",
       "1360  v8edg8            [deleted]      9 2022-06-09 11:08:00       0   \n",
       "1361  v8eh0a      FederalEngineer   1666 2022-06-09 11:14:22       0   \n",
       "\n",
       "                                                   text  \n",
       "1357                ferrari is bull mini-sectors:baku.   \n",
       "1358  [mohammad men player] is a driver, a have alwa...  \n",
       "1359  [mohammad men player] is a driver, a have alwa...  \n",
       "1360  [sky sports F1] \"everybody has ﻿the right to t...  \n",
       "1361                              ferrari new mirrors.   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 400 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1730 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 641 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 629 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 616 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 623 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 435 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 740 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 633 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 631 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 757 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1071 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 898 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 592 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1332 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1149 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 472 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1813 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 1165 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 522 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 388 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 398 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 403 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 408 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 506 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 533 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 459 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 927 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 405 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 521 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 555 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 481 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 467 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 437 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 691 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 464 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 476 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 658 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 396 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 391 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 386 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 910 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 818 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 432 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 604 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 789 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 606 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 447 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 404 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 494 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 469 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 395 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 443 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 730 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 829 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 439 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 545 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 644 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 389 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 445 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 450 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 451 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 851 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 482 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 933 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 428 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 448 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 426 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\gliner\\data_processing\\processor.py:296: UserWarning: Sentence of length 596 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6224\n",
      "1923.515023 filter time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.5485634 sentiment time\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DriverFullName'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DriverFullName'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# final prediction\u001b[39;00m\n\u001b[0;32m     68\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n\u001b[1;32m---> 69\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_weekend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_events\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistorical_score_contribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m((end \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m9\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal pred time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mprediction\u001b[1;34m(n_event, final_scores, n_events, historical_score_contribution)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction\u001b[39m(n_event, final_scores, n_events\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, historical_score_contribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#func to import historical data for this race\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     historical_data \u001b[38;5;241m=\u001b[39m get_top20(n_event)\n\u001b[1;32m----> 4\u001b[0m     historical_scores \u001b[38;5;241m=\u001b[39m {\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDriverFullName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m historical_data\u001b[38;5;241m.\u001b[39miterrows()}\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_events):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m#func to import historical data for one of the last 5 races\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         historical_data \u001b[38;5;241m=\u001b[39m get_top20(n_event \u001b[38;5;241m-\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\raf\\Documents\\GitHub\\f1-subreddits-nlp\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DriverFullName'"
     ]
    }
   ],
   "source": [
    "text = 'Carlos Sainz is loving this upgraded car, good top 3 for the race tomorrow! I disagree with you, verstappening will definitely finish first. I think BOT will finish behind NOR, who will probably finish 7th. That\\'s my opinion at least... I predict that the RedBulls with finish 1-2. Nah, the Danish driver from Haas will almost certainly finish in points! Stroll on the podium and Vettel in points. I like cookies!'\n",
    "debug = False\n",
    "import dask.dataframe as dd\n",
    "\n",
    "if debug:\n",
    "    doc = nlp(text)\n",
    "    posts_df = pd.DataFrame({'text': tuple(sentence.text for sentence in doc.sents)})\n",
    "else:\n",
    "    posts_df = load_f1_df()\n",
    "\n",
    "# with display_full_dataframe():\n",
    "#     display(hide_index(df.head()))\n",
    "\n",
    "# df['text'] = df['text'].apply(preprocessing.correct_spelling_in_text_spacy)\n",
    "# df = df[df['text'].apply(has_prediction)]\n",
    "\n",
    "def display_posts_df(n=3):\n",
    "    global posts_df\n",
    "    \n",
    "    with display_full_dataframe():\n",
    "        display(hide_index(posts_df.head(n)))\n",
    "\n",
    "\n",
    "\n",
    "for index, race_weekend in schedule.iterrows():\n",
    "    #load relevant post\n",
    "    first_post_at = typing.cast(dt.datetime, race_weekend['Session1DateUtc']) - dt.timedelta(days=1)\n",
    "    last_post_at = typing.cast(dt.datetime, race_weekend['Session5DateUtc'])\n",
    "    posts_df = posts_df[\n",
    "        (posts_df['created_utc'] >= first_post_at) &\n",
    "        (posts_df['created_utc'] <= last_post_at)\n",
    "    ]\n",
    "    print(len(posts_df))\n",
    "    display(posts_df.head())\n",
    "    display_posts_df()\n",
    "    start = time.perf_counter_ns()\n",
    "    posts_df['text'] = posts_df['text'].apply(preprocessing.correct_spelling_in_text_spacy)\n",
    "    end = time.perf_counter_ns()\n",
    "    print((end - start) / 10 ** 9, \"spell time\")\n",
    "    display(posts_df.head())\n",
    "    # only predictions\n",
    "    start = time.perf_counter_ns()\n",
    "    \n",
    "    # posts_ddf = dd.from_pandas(posts_df, npartitions=16)\n",
    "    # display(posts_ddf.head())\n",
    "    # has_prediction = posts_ddf['text'].map_partitions(has_prediction, meta=('text', 'bool'))\n",
    "    # print(type(has_prediction))\n",
    "    # print(has_prediction)\n",
    "    # print(has_prediction.compute())\n",
    "    # posts_df = posts_ddf[has_prediction].compute()\n",
    "    \n",
    "    posts_df = posts_df[posts_df['text'].apply(has_prediction)]\n",
    "    print(len(posts_df))\n",
    "    # with display_full_dataframe():\n",
    "    #     display(predictions_df.head())\n",
    "\n",
    "    end = time.perf_counter_ns()\n",
    "    print((end - start) / 10 ** 9, \"filter time\")\n",
    "\n",
    "    # sentiment score\n",
    "    start = time.perf_counter_ns()\n",
    "    sentiment = driver_sentiment(posts_df[\"text\"], F1_names)\n",
    "    scores = final_scores(sentiment)\n",
    "    end = time.perf_counter_ns()\n",
    "    print((end - start) / 10 ** 9, \"sentiment time\")\n",
    "\n",
    "    # final prediction\n",
    "    start = time.perf_counter_ns()\n",
    "    pred = prediction(race_weekend, scores, n_events=5, historical_score_contribution=0.4)\n",
    "    end = time.perf_counter_ns()\n",
    "    print((end - start) / 10 ** 9, \"final pred time\")\n",
    "    print(pred)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kevin magnussen': {'positive': 0.257857841749986,\n",
       "  'neutral': 0.3314998320614298,\n",
       "  'negative': 0.41064231966932613,\n",
       "  'count': 3},\n",
       " 'charles leclerc': {'positive': 0.3397441710694693,\n",
       "  'neutral': 0.5532032469636761,\n",
       "  'negative': 0.10705259200767614,\n",
       "  'count': 16},\n",
       " 'daniel ricciardo': {'positive': 0.3152850657235831,\n",
       "  'neutral': 0.2753738704137504,\n",
       "  'negative': 0.4093410685658455,\n",
       "  'count': 5},\n",
       " 'max verstappen': {'positive': 0.23604163890430593,\n",
       "  'neutral': 0.48895597457200946,\n",
       "  'negative': 0.27500236858887706,\n",
       "  'count': 17},\n",
       " 'fernando alonso': {'positive': 0.13056333363056183,\n",
       "  'neutral': 0.7456882869203886,\n",
       "  'negative': 0.12374836454788844,\n",
       "  'count': 6},\n",
       " 'zhou guanyu': {'positive': 0.09164906479418278,\n",
       "  'neutral': 0.8717689216136932,\n",
       "  'negative': 0.03658195259049535,\n",
       "  'count': 2},\n",
       " 'liam lawson': {'positive': 0.3533530831336975,\n",
       "  'neutral': 0.0507567934691906,\n",
       "  'negative': 0.5958901047706604,\n",
       "  'count': 1},\n",
       " 'george russell': {'positive': 0.4437535772449337,\n",
       "  'neutral': 0.26836115834885277,\n",
       "  'negative': 0.2878852531357552,\n",
       "  'count': 8},\n",
       " 'lando norris': {'positive': 0.3317953424528241,\n",
       "  'neutral': 0.22545468248426914,\n",
       "  'negative': 0.4427499773912132,\n",
       "  'count': 5},\n",
       " 'carlos sainz': {'positive': 0.39598067235201595,\n",
       "  'neutral': 0.27653967468068,\n",
       "  'negative': 0.32747965659946204,\n",
       "  'count': 5},\n",
       " 'oscar piastri': {'positive': 0.3416230157017708,\n",
       "  'neutral': 0.4698391892015934,\n",
       "  'negative': 0.18853786028921604,\n",
       "  'count': 2},\n",
       " 'nyck de vries': {'positive': 0.0,\n",
       "  'neutral': 0.0,\n",
       "  'negative': 0.0,\n",
       "  'count': 0},\n",
       " 'pierre gasly': {'positive': 0.1802765130996704,\n",
       "  'neutral': 0.8030995726585388,\n",
       "  'negative': 0.01662399433553219,\n",
       "  'count': 1},\n",
       " 'lance stroll': {'positive': 0.3146673319861293,\n",
       "  'neutral': 0.28876374510582536,\n",
       "  'negative': 0.39656891611715156,\n",
       "  'count': 6},\n",
       " 'yuki tsunoda': {'positive': 0.24334495266278586,\n",
       "  'neutral': 0.4960106710592906,\n",
       "  'negative': 0.2606443762779236,\n",
       "  'count': 3},\n",
       " 'esteban ocon': {'positive': 0.1474243700504303,\n",
       "  'neutral': 0.8368359804153442,\n",
       "  'negative': 0.01573963090777397,\n",
       "  'count': 1},\n",
       " 'alexander albon': {'positive': 0.17812170088291168,\n",
       "  'neutral': 0.8053069710731506,\n",
       "  'negative': 0.016571370884776115,\n",
       "  'count': 1},\n",
       " 'logan sargeant': {'positive': 0.8495665192604065,\n",
       "  'neutral': 0.04773769527673721,\n",
       "  'negative': 0.1026957631111145,\n",
       "  'count': 1},\n",
       " 'valtteri bottas': {'positive': 0.12714153279860815,\n",
       "  'neutral': 0.6050151412685713,\n",
       "  'negative': 0.26784334766368073,\n",
       "  'count': 3},\n",
       " 'mick schumacher': {'positive': 0.1209278458263725,\n",
       "  'neutral': 0.2139720393655201,\n",
       "  'negative': 0.6651001290107766,\n",
       "  'count': 6},\n",
       " 'lewis hamilton': {'positive': 0.15843482633224792,\n",
       "  'neutral': 0.31798971807584164,\n",
       "  'negative': 0.5235754591309362,\n",
       "  'count': 45},\n",
       " 'nicholas latifi': {'positive': 0.17549994587898254,\n",
       "  'neutral': 0.8079442977905273,\n",
       "  'negative': 0.01655581407248974,\n",
       "  'count': 1},\n",
       " 'nico hulkenberg': {'positive': 0.6500668525695801,\n",
       "  'neutral': 0.18822193145751953,\n",
       "  'negative': 0.161711186170578,\n",
       "  'count': 1},\n",
       " 'sebastian vettel': {'positive': 0.30614877096377313,\n",
       "  'neutral': 0.13608438079245389,\n",
       "  'negative': 0.5577668447047472,\n",
       "  'count': 10},\n",
       " 'sergio perez': {'positive': 0.4103610375896096,\n",
       "  'neutral': 0.5575076304376125,\n",
       "  'negative': 0.0321313291011999,\n",
       "  'count': 12}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers ranked by (positive - negative score):\n",
      "Logan Sargeant: 0.7469\n",
      "Nico Hulkenberg: 0.4884\n",
      "Sergio Perez: 0.3782\n",
      "Charles Leclerc: 0.2327\n",
      "Pierre Gasly: 0.1637\n",
      "Alexander Albon: 0.1616\n",
      "Nicholas Latifi: 0.1589\n",
      "George Russell: 0.1559\n",
      "Oscar Piastri: 0.1531\n",
      "Esteban Ocon: 0.1317\n",
      "Carlos Sainz: 0.0685\n",
      "Zhou Guanyu: 0.0551\n",
      "Fernando Alonso: 0.0068\n",
      "Yuki Tsunoda: -0.0173\n",
      "Max Verstappen: -0.0390\n",
      "Lance Stroll: -0.0819\n",
      "Daniel Ricciardo: -0.0941\n",
      "Lando Norris: -0.1110\n",
      "Valtteri Bottas: -0.1407\n",
      "Kevin Magnussen: -0.1528\n",
      "Liam Lawson: -0.2425\n",
      "Sebastian Vettel: -0.2516\n",
      "Lewis Hamilton: -0.3651\n",
      "Mick Schumacher: -0.5442\n"
     ]
    }
   ],
   "source": [
    "display(sentiment)\n",
    "print(\"Drivers ranked by (positive - negative score):\")\n",
    "for driver, score in scores:\n",
    "    print(f\"{driver}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
